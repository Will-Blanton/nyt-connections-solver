{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Author: Will Blanton",
   "id": "bfc8b95f1aa52b31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "58f3a617b097893e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:55.678929Z",
     "start_time": "2025-05-07T22:11:51.304552Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import torch_geometric\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import knn_graph"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Helper Functions",
   "id": "42e51090bd299a90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Dataset",
   "id": "cf9cb0e43f07f9f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:55.686361Z",
     "start_time": "2025-05-07T22:11:55.678929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(0)\n",
    "torch.manual_seed(0)"
   ],
   "id": "558c49f1dd2cc80b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x18e0ace1f30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:55.689217Z",
     "start_time": "2025-05-07T22:11:55.686361Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Cuda available: {torch.cuda.is_available()}\")",
   "id": "6b95ae443a15a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:56.763943Z",
     "start_time": "2025-05-07T22:11:55.689217Z"
    }
   },
   "cell_type": "code",
   "source": "word_embedder = SentenceTransformer('all-MiniLM-L6-v2')",
   "id": "7d77bc8343505cac",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:56.798491Z",
     "start_time": "2025-05-07T22:11:56.764948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "connections_df = pd.read_csv('data/connections.csv', index_col=0)\n",
    "connections_df.drop(columns='category', inplace=True)\n",
    "\n",
    "# fix issues with incorrect format... (not worth going in and adding a mechanism to correct...)\n",
    "connections_df.loc[1298, \"connections\"] = \"['line', 'plane', 'point', 'solid']\"\n",
    "connections_df.loc[1892, \"connections\"] = \"['abyss', 'fly', 'matrix', 'thing']\"\n",
    "\n",
    "# remove april fools samples since they include emojis or other potentially noisy samples\n",
    "connections_df = connections_df[~connections_df['date'].str.contains(\"04-01\")]\n",
    "connections_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "connections_df['connections'] = connections_df['connections'].apply(ast.literal_eval)\n",
    "connections_df"
   ],
   "id": "77ea9b0125b7dbb1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            date                     connections\n",
       "0     2023-06-12   [kayak, level, mom, race car]\n",
       "1     2023-06-12    [option, return, shift, tab]\n",
       "2     2023-06-12       [bucks, heat, jazz, nets]\n",
       "3     2023-06-12       [hail, rain, sleet, snow]\n",
       "4     2023-06-13          [are, queue, sea, why]\n",
       "...          ...                             ...\n",
       "2751  2025-05-01     [pot, prize, purse, reward]\n",
       "2752  2025-05-02  [bottle, break, goose, turtle]\n",
       "2753  2025-05-02          [dog, link, rib, wing]\n",
       "2754  2025-05-02    [brace, post, prop, support]\n",
       "2755  2025-05-02   [bust, relief, statue, torso]\n",
       "\n",
       "[2756 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>connections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>[kayak, level, mom, race car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>[option, return, shift, tab]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>[bucks, heat, jazz, nets]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-12</td>\n",
       "      <td>[hail, rain, sleet, snow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-13</td>\n",
       "      <td>[are, queue, sea, why]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>[pot, prize, purse, reward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>[bottle, break, goose, turtle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>[dog, link, rib, wing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>[brace, post, prop, support]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>[bust, relief, statue, torso]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2756 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:56.801998Z",
     "start_time": "2025-05-07T22:11:56.798491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConnectionsData(Data):\n",
    "    # needed to adjust the edge group indices for batching\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'group_indices':\n",
    "            # group_indices refers to node indices → so shift by number of nodes\n",
    "            return self.x.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)"
   ],
   "id": "22641c6edd82fb77",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:56.812016Z",
     "start_time": "2025-05-07T22:11:56.801998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "\n",
    "TODO: add more features to handle complicated cases\n",
    "- phonetic word embeddings\n",
    "- character-level embeddings (either trained via RNN or pre-trained)\n",
    "- n-gram?\n",
    "\"\"\"\n",
    "class ConnectionsGraphDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        puzzle_df: pd.DataFrame,\n",
    "        word_emb_model: SentenceTransformer,\n",
    "        negative_ratio: int = 3,\n",
    "        include_purple: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.puzzle_df = puzzle_df\n",
    "        self.negative_ratio = negative_ratio\n",
    "        self.include_purple = include_purple\n",
    "        self.data_list = []\n",
    "\n",
    "        # get lists of words for each puzzle \n",
    "        words_per_date = (\n",
    "            self.puzzle_df\n",
    "            .groupby('date')['connections']\n",
    "            .agg(lambda lists: list(itertools.chain.from_iterable(lists)))\n",
    "        )\n",
    "\n",
    "        # create data object for each puzzle\n",
    "        for date, word_list in words_per_date.items():\n",
    "            if len(word_list) != 16:\n",
    "                raise ValueError(f'Word list length {len(word_list)} does not match 16 words')\n",
    "            data = self._build_single_graph(date, word_list, word_emb_model)\n",
    "            self.data_list.append(data)\n",
    "\n",
    "    def _build_single_graph(self, date, word_list, word_emb_model):\n",
    "        \n",
    "        # create node features \n",
    "        x = word_emb_model.encode(word_list, convert_to_tensor=True)\n",
    "        word2idx = {w: i for i, w in enumerate(word_list)}\n",
    "\n",
    "        edge_index, edge_attr = self._make_graph(x)\n",
    "\n",
    "        positives = self._collect_positives(date, word2idx)\n",
    "        negatives = self._sample_negatives(len(word_list), positives)\n",
    "\n",
    "        # remove purple pairs (already handled for negatives)\n",
    "        if not self.include_purple:\n",
    "            positives = positives[:-1]\n",
    "\n",
    "        group_indices = torch.tensor(positives + negatives, dtype=torch.long)\n",
    "        group_labels = torch.tensor(\n",
    "            [1]*len(positives) + [0]*len(negatives),\n",
    "            dtype=torch.float\n",
    "        )\n",
    "        \n",
    "        data = ConnectionsData(\n",
    "            x=x,    # (16, embed_dim)\n",
    "            edge_index=edge_index,  # (2, num_edges)\n",
    "            edge_attr=edge_attr, # (num_edges, 1)\n",
    "            group_indices=group_indices,  # (num_groups, 4)\n",
    "            group_labels=group_labels     # (num_groups,)\n",
    "        )\n",
    "\n",
    "        data.word_list = word_list\n",
    "        return data\n",
    "\n",
    "    def _make_graph(self, x, k=6):\n",
    "        \"\"\"\n",
    "        Construct KNN graph for words\n",
    "        :param x: \n",
    "        :param k: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        \n",
    "        edge_index = knn_graph(x, k=k, batch=None, loop=False, cosine=True)\n",
    "\n",
    "        # leave as directed since knn relationship is asymmetrical \n",
    "        # edge_index = to_undirected(edge_index)\n",
    "\n",
    "        # edge attributes (cosine similarity)\n",
    "        src = x[edge_index[0]]\n",
    "        dst = x[edge_index[1]]\n",
    "        edge_attr = cosine_similarity(src, dst).unsqueeze(1)\n",
    "\n",
    "        return edge_index, edge_attr\n",
    "\n",
    "    def _collect_positives(self, date, word2idx):\n",
    "        subset = self.puzzle_df[self.puzzle_df['date'] == date]\n",
    "        positives = []\n",
    "        for _, row in subset.iterrows():\n",
    "            idxs = [word2idx[w] for w in row['connections']]\n",
    "            positives.append(sorted(idxs))\n",
    "        return positives\n",
    "\n",
    "    def _sample_negatives(self, num_nodes, positives):\n",
    "        positive_set = set(tuple(g) for g in positives)\n",
    "        all_quads = list(itertools.combinations(range(num_nodes), 4))\n",
    "        random.shuffle(all_quads)\n",
    "\n",
    "        negatives = []\n",
    "\n",
    "        if self.include_purple: \n",
    "            max_neg = self.negative_ratio * len(positives)\n",
    "        else:\n",
    "            max_neg = self.negative_ratio * (len(positives) - 1)\n",
    "        \n",
    "        for quad in all_quads:\n",
    "            if len(negatives) >= max_neg:\n",
    "                break\n",
    "            if tuple(quad) not in positive_set:\n",
    "                negatives.append(list(quad))\n",
    "        return negatives\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx]    "
   ],
   "id": "14b00bf121815d51",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:11:56.824639Z",
     "start_time": "2025-05-07T22:11:56.812016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split data\n",
    "dates = connections_df[\"date\"].unique()\n",
    "train_idx = random.sample(range(len(dates)), k=int(len(dates) * .8))\n",
    "train_dates = dates[train_idx]\n",
    "test_dates = dates[~np.isin(range(len(dates)), train_idx)]\n",
    "\n",
    "test_dates = np.random.permutation(test_dates)\n",
    "split_idx = len(test_dates) // 2\n",
    "val_dates = test_dates[split_idx:]\n",
    "test_dates = test_dates[:split_idx]\n",
    "\n",
    "print(f\"Total Length: {len(dates)}\")\n",
    "print(f\"Train length: {len(train_dates)}\")\n",
    "print(f\"Val length: {len(val_dates)}\")\n",
    "print(f\"Test length: {len(test_dates)}\")"
   ],
   "id": "9b83dd9ed75d2b6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 689\n",
      "Train length: 551\n",
      "Val length: 69\n",
      "Test length: 69\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.249722Z",
     "start_time": "2025-05-07T22:11:56.824639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 64\n",
    "NEGATIVE_RATIO = 3\n",
    "INCLUDE_PURPLE = False\n",
    "\n",
    "train = ConnectionsGraphDataset(connections_df.loc[connections_df[\"date\"].isin(train_dates)], word_embedder, negative_ratio=NEGATIVE_RATIO, include_purple=INCLUDE_PURPLE)\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val = ConnectionsGraphDataset(connections_df.loc[connections_df[\"date\"].isin(val_dates)], word_embedder, negative_ratio=NEGATIVE_RATIO, include_purple=INCLUDE_PURPLE)\n",
    "val_loader = DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test = ConnectionsGraphDataset(connections_df.loc[connections_df[\"date\"].isin(test_dates)], word_embedder, negative_ratio=NEGATIVE_RATIO, include_purple=INCLUDE_PURPLE)\n",
    "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "id": "39c29eb28524c1cc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.253394Z",
     "start_time": "2025-05-07T22:12:02.249722Z"
    }
   },
   "cell_type": "code",
   "source": "del word_embedder",
   "id": "a81be0ffe8777855",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.264592Z",
     "start_time": "2025-05-07T22:12:02.253394Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_SAMPLES = (4 if INCLUDE_PURPLE else 3) * (NEGATIVE_RATIO + 1)",
   "id": "2325155f17a0e203",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.279918Z",
     "start_time": "2025-05-07T22:12:02.264592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in DataLoader(val, batch_size=2, shuffle=True):\n",
    "    print(batch)\n",
    "    print(batch.group_indices)\n",
    "\n",
    "    x = batch.x\n",
    "    group_embeds = x[batch.group_indices]\n",
    "    print(group_embeds.view(group_embeds.size(0), -1).shape)\n",
    "    \n",
    "    break"
   ],
   "id": "c32813e2d229c248",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConnectionsDataBatch(x=[32, 384], edge_index=[2, 192], edge_attr=[192, 1], group_indices=[24, 4], group_labels=[24], word_list=[2], batch=[32], ptr=[3])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [ 1,  3,  5,  8],\n",
      "        [ 4,  5, 10, 11],\n",
      "        [ 3,  5,  8, 14],\n",
      "        [ 0,  2,  4, 15],\n",
      "        [ 3,  4,  8, 12],\n",
      "        [ 0,  6,  7,  8],\n",
      "        [ 5,  7, 12, 14],\n",
      "        [ 6, 11, 13, 15],\n",
      "        [ 6,  8, 10, 12],\n",
      "        [16, 17, 18, 19],\n",
      "        [20, 21, 22, 23],\n",
      "        [24, 25, 26, 27],\n",
      "        [17, 26, 27, 28],\n",
      "        [21, 22, 30, 31],\n",
      "        [20, 25, 26, 30],\n",
      "        [19, 23, 24, 30],\n",
      "        [18, 21, 22, 27],\n",
      "        [17, 23, 24, 27],\n",
      "        [18, 24, 25, 31],\n",
      "        [17, 23, 28, 31],\n",
      "        [20, 25, 28, 29]])\n",
      "torch.Size([24, 1536])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Architecture",
   "id": "e72b1a0e6a350400"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.284140Z",
     "start_time": "2025-05-07T22:12:02.279918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class GraphEncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, local_heads, global_heads, dropout, edge_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.local_conv = GATv2Conv(\n",
    "            in_channels=hidden_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            heads=local_heads,\n",
    "            edge_dim=edge_dim,\n",
    "            dropout=dropout,\n",
    "            concat=False\n",
    "        )\n",
    "        \n",
    "        self.global_attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=global_heads,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Dropout + LayerNorm\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        residual = x\n",
    "\n",
    "        x = self.local_conv(x, edge_index, edge_attr)\n",
    "\n",
    "        x = x.unsqueeze(0)\n",
    "        x, _ = self.global_attn(x, x, x)\n",
    "        x = x.squeeze(0)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm(x + residual)\n",
    "\n",
    "        return x"
   ],
   "id": "5be284ab1593f851",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.294098Z",
     "start_time": "2025-05-07T22:12:02.285145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO: implement an auto-regressive variant that builds groups instead of validating groups\n",
    "class ConnectionsGNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim,\n",
    "            num_layers=1,\n",
    "            hidden_size=256,\n",
    "            output_size=1,\n",
    "            attn_heads=8,\n",
    "            agg_heads=2,\n",
    "            dropout=0.2,\n",
    "            edge_dim=1\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin_proj = nn.Linear(in_dim, hidden_size)\n",
    "        \n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            local_heads = attn_heads[i] if isinstance(attn_heads, list) else attn_heads\n",
    "            self.layers.append(GraphEncoderLayer(hidden_size, local_heads, 2, dropout + .5, edge_dim))\n",
    "\n",
    "        # batch_first so dim 1 is considered as the sequence (even though technically not a batch)\n",
    "        self.attn_agg = nn.MultiheadAttention(hidden_size, agg_heads, dropout=dropout, batch_first=True)\n",
    "            \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.LayerNorm(hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_size // 4, output_size)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, group_indices):\n",
    "        \n",
    "        x = self.lin_proj(x)    # (num_nodes, in_dim) -> (num_nodes, hidden_dim)\n",
    "\n",
    "        # compute graph embeddings \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_attr) # (num_nodes, hidden_dim)\n",
    "            \n",
    "        # aggregate groups for final scores\n",
    "        group_embs = x[group_indices]   # (num_groups, 4, hidden_dim)\n",
    "        group_embs, _ = self.attn_agg(group_embs, group_embs, group_embs)   # (num_groups, 4, hidden_dim)\n",
    "        group_embs, _ = group_embs.max(dim=1)   # (num_groups, hidden_dim)\n",
    "        \n",
    "        logits = self.out(group_embs)    # (num_groups, 1)\n",
    "        return logits.squeeze(-1)   # (num_groups,)"
   ],
   "id": "f2bb1f25ca556d06",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Model",
   "id": "111b9b98af60c988"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.302616Z",
     "start_time": "2025-05-07T22:12:02.294098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_auc(logits, labels):\n",
    "    \"\"\"\n",
    "    logits: (batch_size,) torch.Tensor (raw logits)\n",
    "    labels: (batch_size,) torch.Tensor (binary labels)\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply sigmoid to get probabilities\n",
    "    probs = torch.sigmoid(logits)\n",
    "\n",
    "    # Move to CPU and numpy\n",
    "    probs = probs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "\n",
    "    # Compute ROC AUC\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "\n",
    "    return auc"
   ],
   "id": "865a681e9ffab8fb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:12:02.309940Z",
     "start_time": "2025-05-07T22:12:02.303119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, loader, loss_fn, device):\n",
    "    model.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            x = batch.x.to(device)\n",
    "            edge_index = batch.edge_index.to(device)\n",
    "            edge_attr = batch.edge_attr.to(device)\n",
    "            group_indices = batch.group_indices.to(device)\n",
    "            y = batch.group_labels.to(device)\n",
    "\n",
    "            logits = model(x, edge_index, edge_attr, group_indices)\n",
    "\n",
    "            # Loss (BCEWithLogits → already mean over batch)\n",
    "            batch_loss = loss_fn(logits, y)\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            # Store for AUC\n",
    "            all_logits.append(logits.detach().cpu())\n",
    "            all_labels.append(y.detach().cpu())\n",
    "\n",
    "    # Compute average loss\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    # Compute AUC → concatenate everything\n",
    "    all_logits = torch.cat(all_logits)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    probs = torch.sigmoid(all_logits).numpy()\n",
    "    labels = all_labels.numpy()\n",
    "\n",
    "    auc = roc_auc_score(labels, probs)\n",
    "\n",
    "    return avg_loss, auc"
   ],
   "id": "14dd187951a36fa5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T22:31:35.208773Z",
     "start_time": "2025-05-07T22:29:16.795087Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/connections_experiment\")\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ConnectionsGNN(\n",
    "    in_dim=384,\n",
    "    num_layers=2,\n",
    "    hidden_size=1024,\n",
    "    output_size=1,\n",
    "    attn_heads=[8, 8, 4, 4, 2, 2],\n",
    "    agg_heads=2,\n",
    "    dropout=0.2,\n",
    "    edge_dim=1 \n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x = batch.x.to(device)\n",
    "        edge_index = batch.edge_index.to(device)\n",
    "        edge_attr = batch.edge_attr.to(device)\n",
    "        group_indices = batch.group_indices.to(device)\n",
    "        y = batch.group_labels.to(device)\n",
    "\n",
    "        logits = model(x, edge_index, edge_attr, group_indices)\n",
    "\n",
    "        batch_loss = loss(logits, y)\n",
    "        train_loss += batch_loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    val_loss, val_auc = evaluate(model, val_loader, loss, device)\n",
    "    test_loss, test_auc = evaluate(model, test_loader, loss, device)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        # --- Tensorboard logging ---\n",
    "        writer.add_scalar(\"loss/train\", train_loss, epoch)\n",
    "        writer.add_scalar(\"loss/val\", val_loss, epoch)\n",
    "        writer.add_scalar(\"loss/test\", test_loss, epoch)\n",
    "\n",
    "        writer.add_scalar(\"auc/val\", val_auc, epoch)\n",
    "        writer.add_scalar(\"auc/test\", test_auc, epoch)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        writer.add_scalar(\"lr\", current_lr, epoch)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            writer.add_histogram(f\"param_hist/{name}\", param, epoch)\n",
    "\n",
    "            if param.grad is not None:\n",
    "                writer.add_histogram(f\"grad_hist/{name}\", param.grad, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val AUC: {val_auc:.4f} | Test Loss: {test_loss:.4f} | Test AUC: {test_auc:.4f}\")"
   ],
   "id": "2ce4e8298d3c17ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train Loss: 0.6323 | Val Loss: 0.5645 | Val AUC: 0.4869 | Test Loss: 0.5645 | Test AUC: 0.4702\n",
      "Epoch 5 | Train Loss: 0.5636 | Val Loss: 0.5624 | Val AUC: 0.4610 | Test Loss: 0.5624 | Test AUC: 0.4662\n",
      "Epoch 10 | Train Loss: 0.5629 | Val Loss: 0.5624 | Val AUC: 0.4605 | Test Loss: 0.5624 | Test AUC: 0.4685\n",
      "Epoch 15 | Train Loss: 0.5633 | Val Loss: 0.5624 | Val AUC: 0.4627 | Test Loss: 0.5624 | Test AUC: 0.4680\n",
      "Epoch 20 | Train Loss: 0.5632 | Val Loss: 0.5624 | Val AUC: 0.4648 | Test Loss: 0.5624 | Test AUC: 0.4684\n",
      "Epoch 25 | Train Loss: 0.5620 | Val Loss: 0.5624 | Val AUC: 0.4674 | Test Loss: 0.5624 | Test AUC: 0.4727\n",
      "Epoch 30 | Train Loss: 0.5628 | Val Loss: 0.5623 | Val AUC: 0.4663 | Test Loss: 0.5623 | Test AUC: 0.4727\n",
      "Epoch 35 | Train Loss: 0.5637 | Val Loss: 0.5623 | Val AUC: 0.4656 | Test Loss: 0.5623 | Test AUC: 0.4733\n",
      "Epoch 40 | Train Loss: 0.5645 | Val Loss: 0.5623 | Val AUC: 0.4659 | Test Loss: 0.5623 | Test AUC: 0.4735\n",
      "Epoch 45 | Train Loss: 0.5632 | Val Loss: 0.5623 | Val AUC: 0.4653 | Test Loss: 0.5623 | Test AUC: 0.4737\n",
      "Epoch 50 | Train Loss: 0.5625 | Val Loss: 0.5623 | Val AUC: 0.4669 | Test Loss: 0.5623 | Test AUC: 0.4716\n",
      "Epoch 55 | Train Loss: 0.5628 | Val Loss: 0.5623 | Val AUC: 0.4651 | Test Loss: 0.5623 | Test AUC: 0.4719\n",
      "Epoch 60 | Train Loss: 0.5636 | Val Loss: 0.5623 | Val AUC: 0.4646 | Test Loss: 0.5623 | Test AUC: 0.4721\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 36\u001B[39m\n\u001B[32m     33\u001B[39m group_indices = batch.group_indices.to(device)\n\u001B[32m     34\u001B[39m y = batch.group_labels.to(device)\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m logits = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroup_indices\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m batch_loss = loss(logits, y)\n\u001B[32m     39\u001B[39m train_loss += batch_loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 48\u001B[39m, in \u001B[36mConnectionsGNN.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_attr, group_indices)\u001B[39m\n\u001B[32m     46\u001B[39m \u001B[38;5;66;03m# compute graph embeddings \u001B[39;00m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layers:\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     x = \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# (num_nodes, hidden_dim)\u001B[39;00m\n\u001B[32m     50\u001B[39m \u001B[38;5;66;03m# aggregate groups for final scores\u001B[39;00m\n\u001B[32m     51\u001B[39m group_embs = x[group_indices]   \u001B[38;5;66;03m# (num_groups, 4, hidden_dim)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 30\u001B[39m, in \u001B[36mGraphEncoderLayer.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_attr)\u001B[39m\n\u001B[32m     27\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, edge_index, edge_attr):\n\u001B[32m     28\u001B[39m     residual = x\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlocal_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m     x = x.unsqueeze(\u001B[32m0\u001B[39m)\n\u001B[32m     33\u001B[39m     x, _ = \u001B[38;5;28mself\u001B[39m.global_attn(x, x, x)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gatv2_conv.py:310\u001B[39m, in \u001B[36mGATv2Conv.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[39m\n\u001B[32m    308\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m x_r \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    309\u001B[39m         num_nodes = \u001B[38;5;28mmin\u001B[39m(num_nodes, x_r.size(\u001B[32m0\u001B[39m))\n\u001B[32m--> \u001B[39m\u001B[32m310\u001B[39m     edge_index, edge_attr = \u001B[43mremove_self_loops\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m        \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    312\u001B[39m     edge_index, edge_attr = add_self_loops(\n\u001B[32m    313\u001B[39m         edge_index, edge_attr, fill_value=\u001B[38;5;28mself\u001B[39m.fill_value,\n\u001B[32m    314\u001B[39m         num_nodes=num_nodes)\n\u001B[32m    315\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, SparseTensor):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:115\u001B[39m, in \u001B[36mremove_self_loops\u001B[39m\u001B[34m(edge_index, edge_attr)\u001B[39m\n\u001B[32m    112\u001B[39m mask = edge_index[\u001B[32m0\u001B[39m] != edge_index[\u001B[32m1\u001B[39m]\n\u001B[32m    113\u001B[39m edge_index = edge_index[:, mask]\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mjit\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_scripting\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, EdgeIndex):\n\u001B[32m    116\u001B[39m     edge_index._is_undirected = is_undirected\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m layout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PyCharmProjects\\nyt-connections-solver\\.venv\\Lib\\site-packages\\torch\\_jit_internal.py:103\u001B[39m, in \u001B[36mis_scripting\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m2\u001B[39m, \u001B[32m7\u001B[39m):\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mglobals\u001B[39m()[\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mBroadcastingList\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m] = BroadcastingList1\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mis_scripting\u001B[39m() -> \u001B[38;5;28mbool\u001B[39m:\n\u001B[32m    104\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    105\u001B[39m \u001B[33;03m    Function that returns True when in compilation and False otherwise. This\u001B[39;00m\n\u001B[32m    106\u001B[39m \u001B[33;03m    is useful especially with the @unused decorator to leave code in your\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    120\u001B[39m \u001B[33;03m                return unsupported_linear_op(x)\u001B[39;00m\n\u001B[32m    121\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    122\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ac9d7faec9a1040e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
